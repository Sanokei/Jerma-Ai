{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Project J: Dataset Creation</h1>\n",
    "<sub>Creates a dataset of Jerma being \"funny\" and everything else that he does including being bad at videogames<sub>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Installs libraries</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install youtube-transcript-api\n",
    "!pip install configparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "import re\n",
    "import os\n",
    "import configparser\n",
    "import json\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Find Config</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configParser = configparser.RawConfigParser()   \n",
    "configFilePath = r''+os.getcwd()+'\\\\config.txt'\n",
    "configParser.read(configFilePath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Read from config</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration = int(configParser.get('variables','iteration'))\n",
    "all_highlight_video_ids = json.loads(configParser.get('variables','highlight_videos'))\n",
    "all_vod_video_ids = json.loads(configParser.get('variables','vod_videos'))\n",
    "min_word_count_per_sentence = int('variables','min_word_count_per_sentence')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Variables</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Candid tags (e.g Music and Laugher)\n",
    "cand = {\"[Laughter]\":\"\",\"[Music]\":\"\",\"[Applause]\":\"\"}\n",
    "# Get current directory\n",
    "current_directory = os.getcwd()\n",
    "#train or test file\n",
    "train_or_test = \"train\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Get rid of cadence</h3>\n",
    "<sub><i>cadence deez nuts fit in your mouth</i></sub>\n",
    "<p>Checks if the line has a tag auto generated by youtube</p>\n",
    "<p>For instance [Music]</p>\n",
    "<p>Line 8: Checks if the list is empty, if not then it replaces the tags with nothing.</p>\n",
    "<p>Line 10: Checks if the line is anything at all, if not then it does not add it to the file</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Get Transcript</h4>\n",
    "<p>I was gonna get the manually created transcript but i realized that the way things are formated would be different with the vod, meaning that the program wont be able to delete files from the neg dataset when trying to delete pos duplicates</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_file(video_ids,file_name):\n",
    "    video_id = video_ids[iteration]\n",
    "    transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)\n",
    "    transcript = highlight_transcript_list.find_generated_transcript(['en'])\n",
    "    tran = transcript.fetch()\n",
    "    file = open(r'{}_Transcript.txt'.format(file_name,'w')\n",
    "\n",
    "    for line in tran:\n",
    "        newLine = line.get(\"text\")\n",
    "        i = \"\" if not [k for k,v in cand.items() if line.get(\"text\") == k] else [k for k,v in cand.items() if line.get(\"text\") == k][0]\n",
    "        newLine = line.get(\"text\").replace(i,\"\")\n",
    "        if newLine.strip():\n",
    "            file.write(newLine+\"\\n\")\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Create Positive Dataset Files</h3>\n",
    "They will be named by {iteration},{line}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_file(train_or_test, pos_or_neg, file_name):\n",
    "    path = current_directory + \"//\" + train_or_test + \"//\" + pos_or_neg + \"//\"\n",
    "    transcript_file = open(r'{}_Transcript.txt'.format(file_name),'r')\n",
    "    tran = transcript_file.readlines()\n",
    "    \n",
    "    for line in range(len(tran)):\n",
    "        individual_file = open(r'{},{}.txt'.format(iteration,line),'w')\n",
    "        text = highlight_tran[line]\n",
    "        \n",
    "        if line == len(tran):\n",
    "            individual_file.write(text.rstrip())\n",
    "            individual_file.close()\n",
    "            break\n",
    "        if len(tran[line + 1].split()) <= min_word_count_per_sentence:\n",
    "            text = text.rstrip() + \" \" + tran[line + 1]\n",
    "            individual_file.write(text.rstrip())\n",
    "            individual_file.close()\n",
    "            continue\n",
    "        elif len(tran[line].split()) > min_word_count_per_sentence:\n",
    "            individual_file.write(text.rstrip())\n",
    "            individual_file.close()\n",
    "            \n",
    "    transcript_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Checks if the highlight data is in the vod</h3>\n",
    "All of the highlight footage will be in the vod data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_file(highlight_file_name,vod_file_name):\n",
    "    with open(r'{}_Transcript.txt'.format(highlight_file_name),'r') as highlight_file:\n",
    "        highlight_lines = highlight_file.readlines()\n",
    "    with open(r'{}_Transcript.txt'.format(vod_file_name),'r') as vod_file:\n",
    "        vod_lines = vod_file.readlines()\n",
    "    with open(r'{}_Transcript.txt'.format(vod_file_name + \"2\"),'w') as new_vod_file:\n",
    "        for highlight_line in highlight_lines:\n",
    "            for vod_line in vod_lines():\n",
    "                if(highlight_line not in vod_line.strip(\"\\n\")):\n",
    "                    vod_file.(vod_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(argv):\n",
    "    try:\n",
    "        opts, args = getopt.getopt(sys.argv[1:],\"ht:i\",[\"trainOrTest=\",\"iteration=\"])\n",
    "    except getopt.GetoptError:\n",
    "        print 'JDatasetCreation.py -t <train of test> -i <current iteration>'\n",
    "        sys.exit(2)\n",
    "    for opt, arg in opts:\n",
    "        if opt.lower() == '-h':\n",
    "            print 'JDatasetCreation.py -t <train of test>'\n",
    "            sys.exit()\n",
    "        elif opt.lower() in (\"-t\", \"--trainortest\"):\n",
    "            if(arg.lower() == \"train\" or arg.lower() == \"test\"):\n",
    "                train_or_test = arg.lower()\n",
    "        elif opt.lower() in (\"-i\",\"--iteration\")\n",
    "            iteration = int(arg)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    main(sys.argv[1:])\n",
    "    \n",
    "    make_file(all_highlight_video_ids[iteration],\"highlight\")\n",
    "    group_file(train_or_test,\"pos\", \"highlight\")\n",
    "    \n",
    "    \n",
    "    make_file(all_vod_video_ids[iteration],\"vod\")\n",
    "    group_file(train_or_test,\"neg\",\"vod\")\n",
    "    check_file(\"highlight\",\"vod\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
