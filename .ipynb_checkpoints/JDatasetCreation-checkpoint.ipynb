{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Project J: Dataset Creation</h1>\n",
    "<sub>Creates a dataset of Jerma being \"funny\" and everything else that he does including being bad at videogames<sub>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Installs libraries</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install youtube-transcript-api\n",
    "!pip install configparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "import configparser\n",
    "import getopt\n",
    "\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Find Config</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configParser = configparser.RawConfigParser()   \n",
    "configFilePath = r''+os.getcwd()+'\\\\config.txt'\n",
    "configParser.read(configFilePath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Read from config</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration = int(configParser.get('variables','iteration'))\n",
    "all_highlight_video_ids = json.loads(configParser.get('variables','highlight_videos'))\n",
    "all_vod_video_ids = json.loads(configParser.get('variables','vod_videos'))\n",
    "min_word_count_per_sentence = int(configParser.get('variables','min_word_count_per_sentence'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Variables</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Candid tags (e.g Music and Laugher)\n",
    "cand = {\"[Laughter]\":\"\",\"[Music]\":\"\",\"[Applause]\":\"\"}\n",
    "# Get current directory\n",
    "current_directory = os.getcwd()\n",
    "# train or test file\n",
    "train_or_test = \"train\"\n",
    "# file path\n",
    "file_path = current_directory + \"\\\\\" + \"temp\" + \"\\\\\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Get rid of cadence</h3>\n",
    "<sub><i>cadence deez nuts fit in your mouth</i></sub>\n",
    "<p>Checks if the line has a tag auto generated by youtube</p>\n",
    "<p>For instance [Music]</p>\n",
    "<p>Line 8: Checks if the list is empty, if not then it replaces the tags with nothing.</p>\n",
    "<p>Line 10: Checks if the line is anything at all, if not then it does not add it to the file</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Get Transcript</h4>\n",
    "<p>I was gonna get the manually created transcript but i realized that the way things are formated would be different with the vod, meaning that the program wont be able to delete files from the neg dataset when trying to delete pos duplicates</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_file(video_id,file_name):\n",
    "    transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)\n",
    "    transcript = transcript_list.find_generated_transcript(['en'])\n",
    "    tran = transcript.fetch()\n",
    "    \n",
    "    with open(r'{}{}_Transcript.txt'.format(file_path,file_name),'w+') as file:\n",
    "        for line in tran:\n",
    "            newLine = line.get(\"text\")\n",
    "            i = \"\" if not [k for k,v in cand.items() if line.get(\"text\") == k] else [k for k,v in cand.items() if line.get(\"text\") == k][0]\n",
    "            newLine = line.get(\"text\").replace(i,\"\")\n",
    "            if newLine.strip():\n",
    "                file.write(newLine+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Create Positive Dataset Files</h3>\n",
    "They will be named by {iteration}_{line}.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_file(text,path,iteration,line):\n",
    "    individual_file = open(r'{}{}_{}.txt'.format(path,iteration,line),'w+')\n",
    "    individual_file.write(text.rstrip())\n",
    "    individual_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_file(train_or_test, pos_or_neg, file_name):\n",
    "    path = current_directory + \"\\\\\" + train_or_test + \"\\\\\" + pos_or_neg + \"\\\\\"\n",
    "    with open(r'{}{}_Transcript.txt'.format(file_path,file_name),'r') as transcript_file:\n",
    "        tran = transcript_file.readlines()\n",
    "        \n",
    "    for line in range(len(tran)):\n",
    "        text = tran[line]\n",
    "        if(not text.strip()):\n",
    "            continue\n",
    "        if line == len(tran) - 1:\n",
    "            create_dataset_file(text,path,iteration,line)\n",
    "            break\n",
    "        if  len(tran[line + 1].split()) <= min_word_count_per_sentence and len(tran[line + 1].split()) > 0:    \n",
    "            text = text.rstrip() + \" \" + tran[line + 1]\n",
    "            create_dataset_file(text,path,iteration,line)\n",
    "            continue\n",
    "        elif len(tran[line].split()) > min_word_count_per_sentence:\n",
    "            create_dataset_file(text,path,iteration,line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Checks if the highlight data is in the vod</h3>\n",
    "All of the highlight footage will be in the vod data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_file(highlight_file_name,vod_file_name):\n",
    "    with open(r'{}{}_Transcript.txt'.format(file_path,highlight_file_name),'r') as highlight_file:\n",
    "        highlight_lines = highlight_file.readlines()\n",
    "    with open(r'{}{}_Transcript.txt'.format(file_path,vod_file_name),'r') as vod_file:\n",
    "        vod_lines = vod_file.readlines()\n",
    "    with open(r'{}{}_Transcript.txt'.format(file_path,vod_file_name + \"2\"),'w+') as new_vod_file:\n",
    "        for highlight_line in highlight_lines:\n",
    "            for vod_line in vod_lines:\n",
    "                if(highlight_line not in vod_line.strip(\"\\n\")):\n",
    "                    with open(r'{}{}_Transcript.txt'.format(file_path,vod_file_name),'w') as vod_file:\n",
    "                        vod_file.write(vod_line)                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(argv):\n",
    "    try:\n",
    "        opts, args = getopt.getopt(argv,\"ht:i\",[\"trainOrTest=\",\"iteration=\"])\n",
    "    except getopt.GetoptError:\n",
    "        print ('JDatasetCreation.py -t <train of test> -i <current iteration>')\n",
    "        sys.exit(2)\n",
    "    for opt, arg in opts:\n",
    "        if opt.lower() == '-h':\n",
    "            print ('JDatasetCreation.py -t <train of test>')\n",
    "            sys.exit()\n",
    "        elif opt.lower() in (\"-t\", \"--trainortest\"):\n",
    "            if(arg.lower() == \"train\" or arg.lower() == \"test\"):\n",
    "                train_or_test = arg.lower()\n",
    "        elif opt.lower() in (\"-i\",\"--iteration\"):\n",
    "            iteration = int(arg)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # main(sys.argv[1:])\n",
    "    make_file(all_highlight_video_ids[iteration],\"highlight\")\n",
    "    group_file(train_or_test,\"pos\", \"highlight\")\n",
    "    \n",
    "    make_file(all_vod_video_ids[iteration],\"vod\")\n",
    "    group_file(train_or_test,\"neg\",\"vod\")\n",
    "    check_file(\"highlight\",\"vod\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
