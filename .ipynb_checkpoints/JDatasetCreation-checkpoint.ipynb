{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Project J: Dataset Creation</h1>\n",
    "<sub>Creates a dataset of Jerma being \"funny\" and everything else that he does including being bad at videogames<sub>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Installs libraries</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install youtube-transcript-api\n",
    "!pip install configparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "import re\n",
    "import os\n",
    "import configparser\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Find Config</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configParser = configparser.RawConfigParser()   \n",
    "configFilePath = r''+os.getcwd()+'\\\\config.txt'\n",
    "configParser.read(configFilePath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Read from config</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration = int(configParser.get('variables','iteration'))\n",
    "all_highlight_video_ids = json.loads(configParser.get('variables','highlight_videos'))\n",
    "all_vod_video_ids = json.loads(configParser.get('variables','vod_videos'))\n",
    "min_word_count_per_sentence = int('variables','min_word_count_per_sentence')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Variables</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO(developer) add your own video_id param via config file\n",
    "highlight_video_id = all_highlight_video_ids[iteration]\n",
    "vod_video_id = all_vod_video_ids[iteration]\n",
    "# Gets all the avialiable transcripts\n",
    "highlight_transcript_list = YouTubeTranscriptApi.list_transcripts(highlight_video_id)\n",
    "vod_transcript_list = YouTubeTranscriptApi.list_transcripts(vod_video_id)\n",
    "# Candid tags (e.g Music and Laugher)\n",
    "cand = {\"[Laughter]\":\"\",\"[Music]\":\"\",\"[Applause]\":\"\"}\n",
    "# Get current directory\n",
    "current_directory = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Get Transcript</h3>\n",
    "<p>I was gonna get the manually created transcript but i realized that the way things are formated would be different with the vod, meaning that the program wont be able to delete files from the neg dataset when trying to delete pos duplicates</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     highlight_transcript = highlight_transcript_list.find_manually_created_transcript(['en'])\n",
    "#     vod_transcript = vod_transcript_list.find_manually_created_transcript(['en'])\n",
    "# except Exception:\n",
    "highlight_transcript = highlight_transcript_list.find_generated_transcript(['en'])\n",
    "vod_transcript = vod_transcript_list.find_generated_transcript(['en'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Get rid of cadence</h3>\n",
    "<sub><i>cadence deez nuts fit in your mouth</i></sub>\n",
    "</br>\n",
    "<p>Checks if the line has a tag auto generated by youtube for instance [Music]</p>\n",
    "<sub>Line 8: Checks if the list is empty, if not then it replaces the tags with nothing.</sub>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highlight_tran = transcript.fetch()\n",
    "highlight_duration = float(highlight_tran[len(highlight_tran)-1].get(\"start\")) + float(highlight_tran[len(highlight_tran)-1].get(\"duration\"))\n",
    "\n",
    "file = open(r'Jerma2ndTranscript.txt','w')\n",
    "\n",
    "for line in highlight_tran:\n",
    "    newLine = line.get(\"text\")\n",
    "    i = \"\" if not [k for k,v in cand.items() if line.get(\"text\") == k] else [k for k,v in cand.items() if line.get(\"text\") == k][0]\n",
    "    newLine = line.get(\"text\").replace(i,\"\")\n",
    "    if newLine.strip():\n",
    "        file.write(newLine+\"\\n\")\n",
    "file.close()\n",
    "\n",
    "file = open(r'Jerma2ndTranscript.txt','r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highlight_tran = file.readlines()\n",
    "\n",
    "for line in range(len(highlight_tran)):\n",
    "    text = highlight_tran[line]\n",
    "    if line == len(highlight_tran):\n",
    "        print(text)\n",
    "        break\n",
    "    if len(highlight_tran[line + 1].split()) <= min_word_count_per_sentence:\n",
    "        text = text.rstrip() + \" \" + highlight_tran[line + 1]\n",
    "        print(text)\n",
    "        continue\n",
    "        \n",
    "    elif len(highlight_tran[line].split()) > min_word_count_per_sentence:\n",
    "        print(text)\n",
    "    \n",
    "file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
